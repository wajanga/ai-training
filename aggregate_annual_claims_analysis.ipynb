{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8aad07",
   "metadata": {},
   "source": [
    "### ==============================================================================\n",
    "### WORKERS COMPENSATION FUND OF TANZANIA - AI TRAINING\n",
    "### MODULE 2: END-TO-END MACHINE LEARNING PROJECT\n",
    "### PROJECT: FORECASTING ANNUAL DISABLING CLAIM VOLUME\n",
    "### =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec9663",
   "metadata": {},
   "source": [
    "We will use historical data from 1968-2023 to build a model that predicts the **Accepted disabling claims** for the next year (e.g., 2024).\n",
    "- Accurately forecasting claim volume is crucial for annual budgeting, resource planning, and staffing at the WCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set some default styles for our plots for better readability\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34322be",
   "metadata": {},
   "source": [
    "#### Step 1: Look at the Big Picture\n",
    "Before writing a single line of ML code, we must understand the objective.\n",
    "- Business Objective: To provide an accurate, data-driven forecast of the annual number of accepted disabling claims to help WCF leadership with budgeting and resource allocation.\n",
    "- Machine Learning Frame:\n",
    "  - Type: Supervised Learning. We have historical data with the \"correct answers\" (the actual number of claims each year).\n",
    "  - Task: Regression (specifically, Time Series Forecasting). We are predicting a number.\n",
    "  - Learning: Batch Learning. We will train the model on all available historical data at once.\n",
    "- Performance Measure: We need a way to measure how \"good\" our model is. For regression, a standard metric is the Root Mean Square Error (RMSE). This will tell us, on average, how many claims our forecast is off by. A lower RMSE is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c40f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the CSV file\n",
    "file_path = './datasets/aggregate_annual_claims.csv'\n",
    "claims = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows to see what the data looks like\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(claims.head())\n",
    "\n",
    "# Display the last 5 rows to see the time range\n",
    "print(\"\\nLast 5 rows of the dataset:\")\n",
    "display(claims.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e37791",
   "metadata": {},
   "source": [
    "#### Step 3: Explore and Visualize the Data to Gain Insights\n",
    "This step, known as Exploratory Data Analysis (EDA), is where we become detectives. We look for patterns, anomalies, and insights that will guide our modeling strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dfdfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a quick summary of the data, including data types and missing values\n",
    "print(\"Data Info:\")\n",
    "claims.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c544213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the core metrics over time.\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "fig.suptitle('Historical WCF Data Exploration (1968-2023)', fontsize=16)\n",
    "\n",
    "# Plot 1: Accepted Disabling Claims\n",
    "axes[0, 0].plot(claims['Year'], claims['Accepted disabling claims'], label='Accepted Claims', color='blue')\n",
    "axes[0, 0].set_title('Total Accepted Disabling Claims Over Time')\n",
    "axes[0, 0].set_ylabel('Number of Claims')\n",
    "\n",
    "# Plot 2: Subject Employees\n",
    "axes[0, 1].plot(claims['Year'], claims['Subject employees'], label='Employees', color='green')\n",
    "axes[0, 1].set_title('Total Subject Employees Over Time')\n",
    "axes[0, 1].set_ylabel('Number of Employees')\n",
    "\n",
    "# Plot 3: Rate of claims per 100 employees\n",
    "axes[1, 0].plot(claims['Year'], claims['Rate: accepted disabling claims per 100 employees'], label='Rate', color='red')\n",
    "axes[1, 0].set_title('Claim Rate per 100 Employees')\n",
    "axes[1, 0].set_ylabel('Rate')\n",
    "\n",
    "# Plot 4: Denied Claims\n",
    "axes[1, 1].plot(claims['Year'], claims['Denied claims'], label='Denied', color='purple')\n",
    "axes[1, 1].set_title('Denied Claims Over Time')\n",
    "axes[1, 1].set_ylabel('Number of Claims')\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.set_xlabel('Year')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634fef3e",
   "metadata": {},
   "source": [
    "#### Step 4: Prepare the Data for Machine Learning\n",
    "This is often the most time-consuming part of a project. We need to clean the data and engineer features that our model can learn from.\n",
    "##### 4.1. The Train-Test Split (Time Series Critical Rule)\n",
    "For time series data, we cannot shuffle the data randomly. We must split it chronologically to simulate a real-world scenario where we use the past to predict the future. We will train our model on data up to a certain point and test it on the years that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cca0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's decide on a split year. We'll train on data up to 2018 and test on 2019-2023.\n",
    "split_year = 2018\n",
    "\n",
    "# For simplicity and due to missing data, let's filter the dataset to start from 1992\n",
    "# where the data is more complete.\n",
    "df_filtered = claims[claims['Year'] >= 1992].copy()\n",
    "\n",
    "train_df = df_filtered[df_filtered['Year'] <= split_year]\n",
    "test_df = df_filtered[df_filtered['Year'] > split_year]\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da05df",
   "metadata": {},
   "source": [
    "##### 4.2. Feature Engineering: Creating Lag Features\n",
    "To use standard regression models for a time series problem, we transform it by creating \"lag\" features. This means we will use the data from the previous year to predict the data for the current year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the features we believe will be most predictive\n",
    "features_to_lag = [\n",
    "    'Subject employees',\n",
    "    'Denied claims',\n",
    "    'Fatality claims',\n",
    "    'Rate: accepted disabling claims per 100 employees'\n",
    "    # Removed 'Accepted disabling claims' to avoid duplicate columns\n",
    " ]\n",
    "\n",
    "# The target variable we want to predict\n",
    "target_col = 'Accepted disabling claims'\n",
    "\n",
    "# Create a new dataframe for our model\n",
    "model_df = df_filtered[['Year', target_col] + features_to_lag].copy()\n",
    "\n",
    "# Create lag features (data from the previous year)\n",
    "for col in features_to_lag:\n",
    "    model_df[f'{col}_lag1'] = model_df[col].shift(1)\n",
    "\n",
    "# Drop rows with NaN values created by the shift operation\n",
    "model_df.dropna(inplace=True)\n",
    "\n",
    "print(\"Dataframe with Lag Features:\")\n",
    "display(model_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f1fe94",
   "metadata": {},
   "source": [
    "To predict Accepted disabling claims for 1993, our model will use the feature values from 1992 (e.g., Accepted disabling claims_lag1, Subject employees_lag1, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110621b7",
   "metadata": {},
   "source": [
    "##### 4.3. Finalizing Features (X) and Labels (y)\n",
    "Now we separate our data into the features (X) our model will learn from, and the target (y) it will try to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our features are the lagged columns\n",
    "feature_cols = [col for col in model_df.columns if '_lag1' in col]\n",
    "X = model_df[feature_cols]\n",
    "\n",
    "# Our target is the current year's claims\n",
    "y = model_df[target_col]\n",
    "\n",
    "# Split the prepared data into train and test sets\n",
    "X_train = X[model_df['Year'] <= split_year]\n",
    "X_test = X[model_df['Year'] > split_year]\n",
    "y_train = y[model_df['Year'] <= split_year]\n",
    "y_test = y[model_df['Year'] > split_year]\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e29670",
   "metadata": {},
   "source": [
    "##### 4.4. Feature Scaling\n",
    "Our features have very different scales (e.g., employees in millions, rates close to 1). We need to standardize them so our model treats them equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d9b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# IMPORTANT: We fit the scaler ONLY on the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# We use the SAME fitted scaler to transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"First 2 rows of scaled training data:\\n\", X_train_scaled[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0b25e",
   "metadata": {},
   "source": [
    "##### Step 5: Select and Train a Model\n",
    "We'll start with a simple model to create a baseline, then try a more complex one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7904e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# --- Model 1: Linear Regression (Baseline) ---\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "lr_train_preds = lr_model.predict(X_train_scaled)\n",
    "lr_train_rmse = np.sqrt(mean_squared_error(y_train, lr_train_preds))\n",
    "print(f\"Linear Regression Training RMSE: {lr_train_rmse:.2f} claims\")\n",
    "\n",
    "# --- Model 2: Random Forest (More Powerful) ---\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on the training set\n",
    "rf_train_preds = rf_model.predict(X_train_scaled)\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_train_preds))\n",
    "print(f\"Random Forest Training RMSE: {rf_train_rmse:.2f} claims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3e06c",
   "metadata": {},
   "source": [
    "#### Step 6: Fine-Tune Your Model\n",
    "We need a more robust way to evaluate our model than just the training score. For time series, we use TimeSeriesSplit for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8215058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "# TimeSeriesSplit ensures we always train on past data to validate on future data\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# We will use GridSearchCV to find the best hyperparameters for our Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# NOTE: We use the unscaled training data here, as we will build a pipeline next.\n",
    "# For now, let's just tune the Random Forest itself.\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=tscv,\n",
    "                           scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters found:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation RMSE: {:.2f} claims\".format(-grid_search.best_score_))\n",
    "\n",
    "# Let's store our best, fine-tuned model\n",
    "final_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8ab3a8",
   "metadata": {},
   "source": [
    "#### Step 7: Present Your Solution (Evaluate on the Test Set)\n",
    "Now is the moment of truth. We will use our fine-tuned model, which has never seen data past 2018, to make forecasts for 2019-2023 and see how it performs against the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the held-out test set\n",
    "final_predictions = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the final RMSE on the test set\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "print(f\"Final Model Test RMSE: {final_rmse:.2f} claims\")\n",
    "\n",
    "# Create a DataFrame to easily plot the results\n",
    "results_df = pd.DataFrame({\n",
    "    'Year': test_df['Year'],\n",
    "    'Actual_Claims': y_test,\n",
    "    'Predicted_Claims': final_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96791bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(model_df[model_df['Year'] <= split_year]['Year'], y_train, label='Training Data', color='gray', linestyle='--')\n",
    "plt.plot(results_df['Year'], results_df['Actual_Claims'], label='Actual Test Data', color='blue', marker='o')\n",
    "plt.plot(results_df['Year'], results_df['Predicted_Claims'], label='Forecasted Data', color='red', marker='x', linestyle=':')\n",
    "\n",
    "plt.title('WCF Disabling Claims: Forecast vs. Actuals')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Accepted Disabling Claims')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b04886c",
   "metadata": {},
   "source": [
    "#### Step 8: Launch, Monitor, and Maintain\n",
    "The project isn't over once the model is built.\n",
    "##### 8.1. Launch (Saving the Model)\n",
    "We need to save our final model so we can use it in a production environment without having to retrain it every time. We'll also save the scaler, as we need it to process new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4680bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the final model and the scaler\n",
    "joblib.dump(final_model, 'aggregate_claims_forecaster.pkl')\n",
    "joblib.dump(scaler, 'aggregate_data_scaler.pkl')\n",
    "\n",
    "print(\"Model and scaler saved successfully.\")\n",
    "\n",
    "# Example of loading and using the model for a new year's prediction\n",
    "# loaded_model = joblib.load('aggregate_claims_forecaster.pkl')\n",
    "# loaded_scaler = joblib.load('aggregate_data_scaler.pkl')\n",
    "# new_data = ... (this would be the data from the most recent year)\n",
    "# new_data_scaled = loaded_scaler.transform(new_data)\n",
    "# forecast = loaded_model.predict(new_data_scaled)\n",
    "# print(f\"Forecast for next year: {forecast[0]:.0f} claims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fddbd1",
   "metadata": {},
   "source": [
    "#### 8.2. Monitor and Maintain\n",
    "- Monitoring: The model's performance should be tracked. At the end of each year, when the actual claim numbers are finalized, we should compare them to our forecast to see if the model's accuracy is degrading (a phenomenon called \"model drift\").\n",
    "- Maintenance: We need an automated process.\n",
    "  1. Collect Data: At the end of each year, add the new, complete data to our historical dataset.\n",
    "  2. Retrain: Run this entire notebook as a script to automatically retrain the model on the newly updated data.\n",
    "  3. Deploy: The newly trained model replaces the old one, ready to make a forecast for the next year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8eff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new cell at the end of the notebook\n",
    "\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the previously defined dataframes if the notebook was restarted\n",
    "# (Assuming train_df, test_df, y_train, y_test etc. are in memory from previous cells)\n",
    "# We will redefine model_df to ensure a clean slate for this new section.\n",
    "file_path = './datasets/aggregate_annual_claims.csv'\n",
    "claims = pd.read_csv(file_path)\n",
    "df_filtered = claims[claims['Year'] >= 1992].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ae34c",
   "metadata": {},
   "source": [
    "#### ==============================================================================\n",
    "#### Step 9: Iterating to Improve Accuracy\n",
    "#### ==============================================================================\n",
    "Our first model gave us a baseline RMSE of **2450.46 claims**. Now, let's apply some of the improvement strategies we discussed to see if we can build a more accurate model.\n",
    "\n",
    "We will focus on two key areas:\n",
    "1.  **Richer Feature Engineering:** Adding more lags, rolling averages, and trend features.\n",
    "2.  **Trying a More Powerful Model:** Using XGBoost, an industry-standard gradient boosting library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new cell\n",
    "\n",
    "# --- 9.1 Richer Feature Engineering ---\n",
    "\n",
    "# Define our core variables again for clarity\n",
    "features_to_lag = [\n",
    "    'Subject employees',\n",
    "    'Denied claims',\n",
    "    'Fatality claims',\n",
    "    'Rate: accepted disabling claims per 100 employees',\n",
    "    'Accepted disabling claims' # We'll lag this as well as a feature\n",
    "]\n",
    "target_col = 'Accepted disabling claims'\n",
    "\n",
    "# Start with a clean, filtered dataframe\n",
    "adv_model_df = df_filtered[['Year'] + features_to_lag].copy()\n",
    "\n",
    "# 1. Add More Lags (up to 3 years)\n",
    "for col in features_to_lag:\n",
    "    for i in range(1, 4): # Lags 1, 2, and 3\n",
    "        adv_model_df[f'{col}_lag{i}'] = adv_model_df[col].shift(i)\n",
    "\n",
    "# 2. Add Rolling Averages (3-year window)\n",
    "for col in features_to_lag:\n",
    "    # The rolling window includes the previous 3 years, so we shift by 1\n",
    "    adv_model_df[f'{col}_3yr_roll_avg'] = adv_model_df[col].rolling(window=3).mean().shift(1)\n",
    "\n",
    "# 3. Add Trend/Difference Features (Year-over-Year change)\n",
    "for col in features_to_lag:\n",
    "    # The difference between last year and the year before\n",
    "    adv_model_df[f'{col}_yoy_change'] = adv_model_df[col].diff().shift(1)\n",
    "\n",
    "# Drop rows with NaN values (the first few years will be incomplete)\n",
    "adv_model_df.dropna(inplace=True)\n",
    "\n",
    "print(\"Advanced Feature Engineering Complete. Example features for the first available year:\")\n",
    "display(adv_model_df.head(1).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd170e",
   "metadata": {},
   "source": [
    "Now we have a much richer set of features for our model to learn from. Let's prepare our new training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5c7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new cell\n",
    "\n",
    "# --- 9.2 Prepare Advanced Train/Test Sets ---\n",
    "\n",
    "split_year = 2018\n",
    "\n",
    "# Define the new feature columns (all columns except Year and the original target)\n",
    "adv_feature_cols = [col for col in adv_model_df.columns if col not in ['Year', target_col]]\n",
    "adv_target_col = target_col\n",
    "\n",
    "X_adv = adv_model_df[adv_feature_cols]\n",
    "y_adv = adv_model_df[adv_target_col]\n",
    "\n",
    "# Split the data chronologically\n",
    "X_train_adv = X_adv[adv_model_df['Year'] <= split_year]\n",
    "X_test_adv = X_adv[adv_model_df['Year'] > split_year]\n",
    "y_train_adv = y_adv[adv_model_df['Year'] <= split_year]\n",
    "y_test_adv = y_adv[adv_model_df['Year'] > split_year]\n",
    "\n",
    "# --- Feature Scaling ---\n",
    "# IMPORTANT: We still fit the scaler ONLY on the new advanced training data\n",
    "adv_scaler = StandardScaler()\n",
    "X_train_adv_scaled = adv_scaler.fit_transform(X_train_adv)\n",
    "X_test_adv_scaled = adv_scaler.transform(X_test_adv)\n",
    "\n",
    "print(\"Advanced Train/Test Split and Scaling Complete.\")\n",
    "print(\"Shape of X_train_adv_scaled:\", X_train_adv_scaled.shape)\n",
    "print(\"Shape of X_test_adv_scaled:\", X_test_adv_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a4041",
   "metadata": {},
   "source": [
    "##### 9.3. Train and Tune a More Powerful Model (XGBoost)\n",
    "XGBoost is a highly optimized gradient boosting library. It's often a top choice for structured/tabular data problems like this. We'll use `GridSearchCV` again to find its best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da53054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new cell\n",
    "\n",
    "# Install xgboost if it's not already in the environment\n",
    "# !pip install xgboost\n",
    "\n",
    "# --- Model 3: XGBoost with Hyperparameter Tuning ---\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# NOTE: This grid is larger and may take a few minutes to run.\n",
    "# For a faster result during the workshop, you can use a smaller grid.\n",
    "# For example: {'n_estimators': [100], 'max_depth': [3, 5], 'learning_rate': [0.1]}\n",
    "xgb_grid_search = GridSearchCV(\n",
    "    xgb.XGBRegressor(random_state=42),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_grid_search.fit(X_train_adv_scaled, y_train_adv)\n",
    "\n",
    "print(\"Best XGBoost Hyperparameters found:\", xgb_grid_search.best_params_)\n",
    "print(\"Best XGBoost Cross-Validation RMSE: {:.2f} claims\".format(-xgb_grid_search.best_score_))\n",
    "\n",
    "# Store our new, improved final model\n",
    "final_model_v2 = xgb_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754ab98",
   "metadata": {},
   "source": [
    "##### 9.4. Final Evaluation and Comparison\n",
    "Let's see if our new features and more powerful model resulted in a better forecast on the unseen test data (2019-2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9fab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a new cell\n",
    "\n",
    "# --- Final Evaluation of the Improved Model ---\n",
    "final_predictions_v2 = final_model_v2.predict(X_test_adv_scaled)\n",
    "final_rmse_v2 = np.sqrt(mean_squared_error(y_test_adv, final_predictions_v2))\n",
    "\n",
    "print(f\"Original Model (Random Forest) Test RMSE: {final_rmse:.2f} claims\")\n",
    "print(f\"IMPROVED Model (XGBoost) Test RMSE: {final_rmse_v2:.2f} claims\")\n",
    "\n",
    "improvement = final_rmse - final_rmse_v2\n",
    "improvement_percent = (improvement / final_rmse) * 100\n",
    "print(f\"Improvement: {improvement:.2f} claims ({improvement_percent:.2f}%)\")\n",
    "\n",
    "\n",
    "# --- Visualize the New vs. Old Forecast ---\n",
    "results_df_v2 = pd.DataFrame({\n",
    "    'Year': test_df['Year'],\n",
    "    'Actual_Claims': y_test_adv,\n",
    "    'Predicted_Claims_v1_RF': final_predictions, # Original model's predictions\n",
    "    'Predicted_Claims_v2_XGB': final_predictions_v2 # New model's predictions\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "# Use the advanced dataset years to match y_train_adv length\n",
    "plt.plot(adv_model_df[adv_model_df['Year'] <= split_year]['Year'], y_train_adv, label='Training Data', color='gray', linestyle='--')\n",
    "plt.plot(results_df_v2['Year'], results_df_v2['Actual_Claims'], label='Actual Test Data', color='blue', marker='o', linewidth=2)\n",
    "plt.plot(results_df_v2['Year'], results_df_v2['Predicted_Claims_v1_RF'], label=f'V1 Forecast (RF) - RMSE: {final_rmse:.0f}', color='orange', marker='s', linestyle=':')\n",
    "plt.plot(results_df_v2['Year'], results_df_v2['Predicted_Claims_v2_XGB'], label=f'V2 Forecast (XGB) - RMSE: {final_rmse_v2:.0f}', color='red', marker='x', linestyle='-')\n",
    "\n",
    "plt.title('Model Improvement: Forecast vs. Actuals')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Accepted Disabling Claims')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "display(results_df_v2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
