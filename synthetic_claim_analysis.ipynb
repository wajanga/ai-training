{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb31cfe8",
   "metadata": {},
   "source": [
    "# WCF AI Training: End-to-End Machine Learning Project\n",
    "## Project: Predicting Claim Fraud and Processing Time\n",
    "---\n",
    "This notebook provides a comprehensive walkthrough of a machine learning project, from understanding the business problem to preparing the model for deployment. We will use a sample dataset of WCF claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0483ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn for preprocessing and modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Metrics and Evaluation\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "# Set plotting styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d477da",
   "metadata": {},
   "source": [
    "### 1. Look at the Big Picture\n",
    "---\n",
    "Before touching the data, we must define our goals and success criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cb463f",
   "metadata": {},
   "source": [
    "#### 1.1 Frame the Problem\n",
    "*   **Business Objective:** To improve the integrity of the claims process by automatically identifying potentially fraudulent claims at the time of filing. This allows the Special Investigations Unit (SIU) to focus their efforts on the highest-risk cases, increasing efficiency and protecting the Fund's resources.\n",
    "*   **Machine Learning Frame:** This is a **supervised, binary classification problem**.\n",
    "    *   **Supervised:** We have historical data with claims already labeled as `Suspected_Fraud` (1) or not (0).\n",
    "    *   **Binary Classification:** We are predicting one of two outcomes: Fraud (1) or Not Fraud (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05023d2",
   "metadata": {},
   "source": [
    "#### 1.2 Select a Performance Measure\n",
    "*   **Accuracy** (the percentage of correct predictions) can be misleading if the data is imbalanced (which it is here). A model that always predicts \"Not Fraud\" might be 99% accurate but is useless.\n",
    "*   **Better Metrics for this problem:**\n",
    "    *   **Precision:** Of all claims we flagged as fraud, how many were actually fraudulent? (Measures the cost of false positives).\n",
    "    *   **Recall (Sensitivity):** Of all the actual fraudulent claims, how many did we successfully catch? (Measures the cost of false negatives).\n",
    "    *   **AUC (Area Under the ROC Curve):** A single number that summarizes the model's ability to distinguish between the two classes. An AUC of 1.0 is perfect; 0.5 is no better than random guessing. We will use **AUC** as our primary optimization metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72131821",
   "metadata": {},
   "source": [
    "#### 1.3 Check the Assumptions\n",
    "*   **Assumption 1:** The historical data is representative of future claims.\n",
    "*   **Assumption 2:** The \"Suspected_Fraud\" label is a reliable ground truth for our training.\n",
    "*   **Assumption 3:** The model's output (a probability score) can be integrated into the existing claims review workflow. We'll assume the SIU can work with a prioritized list of high-probability claims."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d2473",
   "metadata": {},
   "source": [
    "### 2. Get the Data\n",
    "---\n",
    "Now, we load the data and prepare it for exploration by creating a stable train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8292003",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/synthetic_sample_claims.csv')\n",
    "print(\"Dataset loaded. Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482825ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nData Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nDistribution of our target variable 'Suspected_Fraud':\")\n",
    "print(df['Suspected_Fraud'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32f411",
   "metadata": {},
   "source": [
    "#### 2.1 Create a Test Set\n",
    "**CRITICAL STEP:** We must create a test set *before* any data exploration to prevent data snooping bias. Because our fraud data is imbalanced, we will use **Stratified Sampling** to ensure both the training and test sets have a similar percentage of fraudulent cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b078e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use StratifiedShuffleSplit to create a single, stable split.\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in splitter.split(df, df['Suspected_Fraud']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "print(\"Training set shape:\", strat_train_set.shape)\n",
    "print(\"Test set shape:\", strat_test_set.shape)\n",
    "\n",
    "print(\"\\nFraud distribution in full dataset:\\n\", df['Suspected_Fraud'].value_counts(normalize=True))\n",
    "print(\"\\nFraud distribution in test set:\\n\", strat_test_set['Suspected_Fraud'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fe197",
   "metadata": {},
   "source": [
    "### 3. Explore and Visualize the Data\n",
    "---\n",
    "Now, using **only the training set**, we'll dive deeper to find patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3dbddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_explore = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for differences between fraudulent and non-fraudulent claims\n",
    "fraud_claims = claims_explore[claims_explore['Suspected_Fraud'] == 1]\n",
    "non_fraud_claims = claims_explore[claims_explore['Suspected_Fraud'] == 0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "sns.histplot(data=claims_explore, x='Claim_Amount_TZS', hue='Suspected_Fraud', kde=True, ax=axes[0])\n",
    "axes[0].set_title('Claim Amount Distribution by Fraud Status')\n",
    "\n",
    "sns.histplot(data=claims_explore, x='Processing_Time_Days', hue='Suspected_Fraud', kde=True, ax=axes[1])\n",
    "axes[1].set_title('Processing Time by Fraud Status')\n",
    "\n",
    "sns.histplot(data=claims_explore, x='Age', hue='Suspected_Fraud', kde=True, ax=axes[2])\n",
    "axes[2].set_title('Claimant Age by Fraud Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b544d",
   "metadata": {},
   "source": [
    "#### 3.1 Look for Correlations\n",
    "Let's see which numerical features are correlated with fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert Suspected_Fraud to numeric for correlation\n",
    "corr_matrix = claims_explore.corr(numeric_only=True)\n",
    "print(corr_matrix[\"Suspected_Fraud\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb4bf7",
   "metadata": {},
   "source": [
    "**Insight:** `Claim_Amount_TZS` and `Processing_Time_Days` seem to have a positive correlation with fraud, which makes business sense. Higher value, longer-to-process claims might be more likely to be fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc2b9e",
   "metadata": {},
   "source": [
    "#### 3.2 Experiment with Attribute Combinations\n",
    "Creating new features (Feature Engineering) is key to improving model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e76558",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_explore['Amount_Per_Day'] = claims_explore['Claim_Amount_TZS'] / (claims_explore['Processing_Time_Days'] + 1) # Add 1 to avoid division by zero\n",
    "claims_explore['Age_Squared'] = claims_explore['Age']**2\n",
    "\n",
    "# Re-check correlations with new features\n",
    "new_corr_matrix = claims_explore.corr(numeric_only=True)\n",
    "print(new_corr_matrix[\"Suspected_Fraud\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c21d8",
   "metadata": {},
   "source": [
    "### 4. Prepare the Data for Machine Learning Algorithms\n",
    "---\n",
    "We will now build a robust preprocessing pipeline. This section is highly technical and critical for production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4bcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = strat_train_set.drop(\"Suspected_Fraud\", axis=1)\n",
    "y_train = strat_train_set[\"Suspected_Fraud\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61233813",
   "metadata": {},
   "source": [
    "#### 4.1 Data Cleaning & Custom Transformers\n",
    "We'll create a custom transformer to perform our feature engineering steps. This makes our pipeline cleaner and more modular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fdcdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Date Features\n",
    "        X_copy['Date_Filed'] = pd.to_datetime(X_copy['Date_Filed'])\n",
    "        X_copy['Filing_Year'] = X_copy['Date_Filed'].dt.year\n",
    "        X_copy['Filing_Month'] = X_copy['Date_Filed'].dt.month\n",
    "        \n",
    "        # Interaction Features\n",
    "        X_copy['Amount_Per_Day'] = X_copy['Claim_Amount_TZS'] / (X_copy['Processing_Time_Days'] + 1)\n",
    "        \n",
    "        # Text-based Features\n",
    "        X_copy['Description_Length'] = X_copy['Injury_Description'].str.len()\n",
    "        \n",
    "        # Drop original columns we no longer need\n",
    "        return X_copy.drop(['Claim_ID', 'Date_Filed', 'Injury_Description', 'Paid_Amount_TZS'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1ce57",
   "metadata": {},
   "source": [
    "#### 4.2 Handling Text, Categorical Attributes, Scaling, and the Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column types from the *engineered* dataframe\n",
    "temp_featurizer = FeatureEngineer()\n",
    "X_train_featured = temp_featurizer.fit_transform(X_train)\n",
    "\n",
    "numerical_features = X_train_featured.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train_featured.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Define individual pipelines for numeric and categorical data\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine everything into a single preprocessor\n",
    "full_preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numerical_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# Create the final, full pipeline that includes feature engineering and preprocessing\n",
    "# We wrap our FeatureEngineer transformer using FunctionTransformer to make it compatible\n",
    "feature_pipeline = Pipeline([\n",
    "    ('feature_engineer', FeatureEngineer()),\n",
    "    ('preprocessor', full_preprocessor)\n",
    "])\n",
    "\n",
    "# Test the pipeline\n",
    "X_train_prepared = feature_pipeline.fit_transform(X_train)\n",
    "print(\"Data preparation pipeline built successfully.\")\n",
    "print(\"Shape of prepared training data:\", X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7145991",
   "metadata": {},
   "source": [
    "### 5. Select and Train a Model\n",
    "---\n",
    "We'll start with a simple baseline (Logistic Regression) and then a more powerful one (Random Forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee19653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a full pipeline that includes the model\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('preparation', feature_pipeline),\n",
    "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on training data (just for a baseline check)\n",
    "y_train_pred_lr = log_reg_pipeline.predict(X_train)\n",
    "print(\"--- Logistic Regression (Baseline) ---\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred_lr))\n",
    "print(classification_report(y_train, y_train_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([\n",
    "    ('preparation', feature_pipeline),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on training data\n",
    "y_train_pred_rf = rf_pipeline.predict(X_train)\n",
    "print(\"--- Random Forest ---\")\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred_rf))\n",
    "print(classification_report(y_train, y_train_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c306413",
   "metadata": {},
   "source": [
    "**Insight:** The Random Forest achieves 100% accuracy and perfect scores on the training data. This is a strong sign of **overfitting**, which we'll address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7056c86",
   "metadata": {},
   "source": [
    "### 6. Fine-Tune the Model\n",
    "---\n",
    "We'll use GridSearchCV to find the best hyperparameters for our Random Forest model and combat overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0285377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a parameter grid to search\n",
    "# We add classifier__ to specify that these parameters are for the 'classifier' step of the pipeline\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [10, 20, None],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# We use Stratified K-Fold for cross-validation\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(rf_pipeline, param_grid_rf, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation AUC score: \", grid_search.best_score_)\n",
    "\n",
    "# The best estimator is now our fine-tuned model\n",
    "final_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f556b",
   "metadata": {},
   "source": [
    "#### 6.1 Analyze the Best Model and its Errors\n",
    "Let's look at what features our tuned model found most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to get the feature names from the preprocessor step\n",
    "preprocessor_step = final_model.named_steps['preparation'].named_steps['preprocessor']\n",
    "cat_features_out = preprocessor_step.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "all_feature_names = np.concatenate([numerical_features, cat_features_out])\n",
    "\n",
    "# Get importances from the classifier step\n",
    "importances = final_model.named_steps['classifier'].feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'feature': all_feature_names, 'importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df.head(15))\n",
    "plt.title('Top 15 Most Important Features for Fraud Detection')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dea01c",
   "metadata": {},
   "source": [
    "#### 6.2 Evaluate the System on the Test Set\n",
    "This is the final step before deployment. We use our **held-out test set** for the first time to get an unbiased estimate of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848434ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate test features and labels\n",
    "X_test = strat_test_set.drop(\"Suspected_Fraud\", axis=1)\n",
    "y_test = strat_test_set[\"Suspected_Fraud\"].copy()\n",
    "\n",
    "# Make predictions on the test set\n",
    "final_predictions = final_model.predict(X_test)\n",
    "final_proba = final_model.predict_proba(X_test)[:, 1] # Probability of being fraud\n",
    "\n",
    "# Print final metrics\n",
    "print(\"--- Final Model Evaluation on Test Set ---\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, final_predictions):.4f}\")\n",
    "print(f\"Test AUC Score: {roc_auc_score(y_test, final_proba):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, final_predictions))\n",
    "\n",
    "# Final Confusion Matrix\n",
    "cm = confusion_matrix(y_test, final_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')\n",
    "plt.title('Final Confusion Matrix on Test Set')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5893dd",
   "metadata": {},
   "source": [
    "### 7. Launch, Monitor, and Maintain the System\n",
    "---\n",
    "The model is built and evaluated. Now we prepare it for production.\n",
    "\n",
    "#### 7.1 Monitoring and Maintenance Plan\n",
    "*   **Launch:** Deploy the saved `wcf_fraud_detection_pipeline.pkl` as a web service (API). The claims processing system will send the data for each new claim to this API.\n",
    "*   **Monitor:**\n",
    "    *   **Performance:** Regularly (e.g., quarterly), compare the model's predictions against the outcomes of investigations to track its real-world precision and recall.\n",
    "    *   **Data Drift:** Monitor the statistical distribution of incoming data. If the average `Claim_Amount_TZS` suddenly doubles, the model's performance may degrade. This should trigger an alert.\n",
    "*   **Maintain:**\n",
    "    *   **Retraining:** Schedule a job to automatically retrain the model on fresh, labeled data (e.g., every 6 months) to keep it up-to-date with new fraud patterns.\n",
    "    *   **Versioning:** Keep versions of the model, so if a new model performs worse, we can easily roll back to the previous version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7351a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the entire pipeline (feature engineering, preprocessing, and model)\n",
    "joblib.dump(final_model, 'wcf_fraud_detection_pipeline.pkl')\n",
    "print(\"Final model pipeline saved to 'wcf_fraud_detection_pipeline.pkl'\")\n",
    "\n",
    "# You can now load this pipeline in another script or a web API\n",
    "# loaded_pipeline = joblib.load('wcf_fraud_detection_pipeline.pkl')\n",
    "# predictions = loaded_pipeline.predict(new_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a601e2",
   "metadata": {},
   "source": [
    "### ==============================================================================\n",
    "### Step 8: Interacting with the Deployed Model\n",
    "### ==============================================================================\n",
    "\n",
    "Now that we have a saved pipeline (`wcf_fraud_detection_pipeline.pkl`), how would another part of the WCF system—like the main claims intake application—actually use it?\n",
    "\n",
    "Let's simulate this process. We will:\n",
    "1.  Load our saved pipeline.\n",
    "2.  Create some new, hypothetical claim data as if it just arrived.\n",
    "3.  Feed this new data to the pipeline to get a fraud prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00315704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the entire pipeline object from the file\n",
    "# This object contains all our steps: feature engineering, scaling, encoding, and the trained model.\n",
    "loaded_fraud_pipeline = joblib.load('wcf_fraud_detection_pipeline.pkl')\n",
    "\n",
    "print(\"Fraud detection pipeline loaded successfully!\")\n",
    "print(\"Pipeline steps:\", loaded_fraud_pipeline.steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0794c",
   "metadata": {},
   "source": [
    "#### Creating New Sample Claims\n",
    "\n",
    "Now, let's create a couple of new, unseen claims. It's crucial that this new data is in the **same raw format** as our original CSV file, with the same column names. The pipeline will handle all the necessary transformations for us.\n",
    "\n",
    "We'll create two examples:\n",
    "*   A \"normal-looking\" claim.\n",
    "*   A \"suspicious-looking\" claim with characteristics that might indicate fraud (e.g., very high claim amount, long processing time, a high-risk sector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The structure must match the original input data EXACTLY.\n",
    "# The pipeline expects all the same columns it was trained on.\n",
    "new_claims_data = {\n",
    "    'Claim_ID': ['WCF2025-0001', 'WCF2025-0002'],\n",
    "    'Date_Filed': ['2024-05-15', '2024-05-16'],\n",
    "    'Region': ['Dar es Salaam', 'Mwanza'],\n",
    "    'Sector': ['Construction', 'Retail'],\n",
    "    'Employer_Size': ['Micro', 'Large'],\n",
    "    'Channel': ['Online Portal', 'Walk-in'],\n",
    "    'Claim_Type': ['Lost Time', 'Permanent Disability'],\n",
    "    'Injured_Gender': ['Male', 'Female'],\n",
    "    'Injury_Type': ['Fracture', 'Sprain/Strain'],\n",
    "    'Age': [28, 55],\n",
    "    'Claim_Amount_TZS': [750000, 7500000], # Claim 2 is very high value\n",
    "    'Processing_Time_Days': [25, 180], # Claim 2 has a very long processing time\n",
    "    'Injury_Description': [\n",
    "        'Worker reported a minor fracture after a slip at the construction site.',\n",
    "        'Complex strain injury with conflicting doctor reports and delayed filing.'\n",
    "    ],\n",
    "    'Claim_Status': ['Pending Review', 'Pending Review'],\n",
    "    # We don't include 'Suspected_Fraud' or 'Paid_Amount_TZS' as these are what we predict or come after.\n",
    "    # The pipeline will ignore the target variable column anyway if it's present.\n",
    "}\n",
    "\n",
    "new_claims_df = pd.DataFrame(new_claims_data)\n",
    "\n",
    "print(\"New claims data created:\")\n",
    "display(new_claims_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c7202f",
   "metadata": {},
   "source": [
    "#### Making Predictions with the Pipeline\n",
    "\n",
    "This is the simplest step. We just call the `.predict()` or `.predict_proba()` method on our loaded pipeline, passing in the new data. The pipeline handles everything internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fraud prediction (0 for Not Fraud, 1 for Suspected Fraud)\n",
    "fraud_predictions = loaded_fraud_pipeline.predict(new_claims_df)\n",
    "\n",
    "# Get the probability scores for each class [Prob(Not Fraud), Prob(Fraud)]\n",
    "fraud_probabilities = loaded_fraud_pipeline.predict_proba(new_claims_df)\n",
    "\n",
    "\n",
    "# --- Display the results in a user-friendly way ---\n",
    "\n",
    "for i in range(len(new_claims_df)):\n",
    "    claim_id = new_claims_df.loc[i, 'Claim_ID']\n",
    "    prediction_label = \"Suspected Fraud\" if fraud_predictions[i] == 1 else \"Not Fraud\"\n",
    "    probability_score = fraud_probabilities[i][1] # Probability of being class '1' (Fraud)\n",
    "    \n",
    "    print(f\"\\n--- Prediction for Claim: {claim_id} ---\")\n",
    "    print(f\"Predicted Outcome: {prediction_label}\")\n",
    "    print(f\"Fraud Probability Score: {probability_score:.2%}\")\n",
    "    \n",
    "    # Add a simple business rule for interpretation\n",
    "    if probability_score > 0.5: # This threshold can be tuned\n",
    "        print(\"Recommendation: Flag for review by Special Investigations Unit.\")\n",
    "    else:\n",
    "        print(\"Recommendation: Proceed with standard processing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
