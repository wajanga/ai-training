{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42844d7c",
   "metadata": {},
   "source": [
    "\n",
    "# Hands-On Lab: Claims Analytics & Fraud Detection\n",
    "\n",
    "**Objectives**\n",
    "- Explore, clean, and visualize claims data.\n",
    "- Detect anomalies (potential fraud) using an unsupervised model.\n",
    "- Summarize injury text fields.\n",
    "- (Optional) Load and compare with the Kaggle *Easy Peasy* dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883646e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install and import libraries\n",
    "#!pip -q install pandas scikit-learn matplotlib nltk kaggle --upgrade\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import nltk\n",
    "import os\n",
    "nltk.download('punkt')\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7fa69",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load the Sample Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try local dataset path first (relative to the notebook's working directory)\n",
    "local_dataset_dir = os.path.join(os.getcwd(), \"datasets\")\n",
    "local_csv_path = os.path.join(local_dataset_dir, \"synthetic_sample_claims.csv\")\n",
    "    \n",
    "# Fallback: absolute path to the repo dataset folder (if running from a subdir)\n",
    "repo_root = \"/Users/aronkondoro/Library/Mobile Documents/com~apple~CloudDocs/Projects/WCF\"\n",
    "fallback_csv_path = os.path.join(repo_root, \"dataset\", \"synthetic_sample_claims.csv\")\n",
    "\n",
    "csv_path = local_csv_path if os.path.exists(local_csv_path) else fallback_csv_path\n",
    "print(f\"Loading CSV from: {csv_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_path, parse_dates=[\"Date_Filed\"]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5873de",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Quick Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a529551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b6f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Suspected_Fraud'].value_counts(normalize=True).rename('share').to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3fff0",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Visualize Claims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b167cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df['Claim_Amount_TZS'], df['Processing_Time_Days'])\n",
    "plt.xlabel(\"Claim Amount (TZS)\")\n",
    "plt.ylabel(\"Processing Time (days)\")\n",
    "plt.title(\"Claims: Amount vs Processing Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df.groupby('Region')['Claim_Amount_TZS'].mean().sort_values().plot(kind='bar')\n",
    "plt.title(\"Average Claim Amount by Region\")\n",
    "plt.ylabel(\"TZS\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e89f00",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Anomaly Detection (Unsupervised)\n",
    "We'll use **IsolationForest** on numerical features to flag potentially unusual claims.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Claim_Amount_TZS', 'Processing_Time_Days', 'Age']].copy()\n",
    "model = IsolationForest(contamination=0.05, random_state=42)\n",
    "df['anomaly'] = model.fit_predict(features)\n",
    "\n",
    "outliers = df[df['anomaly'] == -1]\n",
    "print(f\"Flagged {len(outliers)} / {len(df)} claims as unusual (~{len(outliers)/len(df):.1%}).\")\n",
    "outliers[['Claim_ID','Claim_Amount_TZS','Processing_Time_Days','Sector','Channel','Suspected_Fraud']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e8515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df['Claim_Amount_TZS'], df['Processing_Time_Days'], c=(df['anomaly']==-1).astype(int))\n",
    "plt.xlabel(\"Claim Amount (TZS)\")\n",
    "plt.ylabel(\"Processing Time (days)\")\n",
    "plt.title(\"Outliers Highlighted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8220f60",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Quick Text Summaries (NLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def summarize_text(text):\n",
    "    sents = sent_tokenize(text or \"\")\n",
    "    return sents[0] if sents else \"\"\n",
    "\n",
    "df['Summary'] = df['Injury_Description'].apply(summarize_text)\n",
    "df[['Claim_ID','Injury_Description','Summary']].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
